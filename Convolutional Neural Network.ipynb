{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\divyesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n",
      "c:\\users\\divyesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\librosa\\util\\decorators.py:9: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.decorators import jit as optional_jit\n"
     ]
    }
   ],
   "source": [
    "### Load necessary libraries ###\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define helper functions ###\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",\n",
    "                     bands=60,frames=41):\n",
    "    def _windows(data, window_size):\n",
    "        start = 0\n",
    "        while start < len(data):\n",
    "            yield int(start), int(start + window_size)\n",
    "            start += (window_size // 2)\n",
    "            \n",
    "    window_size = 512 * (frames - 1)\n",
    "    features, labels = [], []\n",
    "    for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "        segment_log_specgrams, segment_labels = [], []\n",
    "        sound_clip,sr = librosa.load(fn)\n",
    "        label = int(fn.split('/')[2].split('-')[1])\n",
    "        for (start,end) in _windows(sound_clip,window_size):\n",
    "            if(len(sound_clip[start:end]) == window_size):\n",
    "                signal = sound_clip[start:end]\n",
    "                melspec = librosa.feature.melspectrogram(signal,n_mels=bands)\n",
    "                logspec = librosa.amplitude_to_db(melspec)\n",
    "                logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                segment_log_specgrams.append(logspec)\n",
    "                segment_labels.append(label)\n",
    "            \n",
    "        segment_log_specgrams = np.asarray(segment_log_specgrams).reshape(\n",
    "            len(segment_log_specgrams),bands,frames,1)\n",
    "        segment_features = np.concatenate((segment_log_specgrams, np.zeros(\n",
    "            np.shape(segment_log_specgrams))), axis=3)\n",
    "        for i in range(len(segment_features)): \n",
    "            segment_features[i, :, :, 1] = librosa.feature.delta(\n",
    "                segment_features[i, :, :, 0])\n",
    "        \n",
    "        if len(segment_features) > 0: # check for empty segments \n",
    "            features.append(segment_features)\n",
    "            labels.append(segment_labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'UrbanSounds8K/processed/fold1.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1e209c08d2a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     np.savez(\"{0}{1}\".format(save_dir, sub_dir), \n\u001b[0;32m     10\u001b[0m              \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m              labels=labels)\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavez\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\divyesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavez\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     \"\"\"\n\u001b[1;32m--> 632\u001b[1;33m     \u001b[0m_savez\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\divyesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZIP_STORED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 730\u001b[1;33m     \u001b[0mzipf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    731\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    732\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\divyesh\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mzipfile_factory\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allowZip64'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\divyesh\\appdata\\local\\programs\\python\\python37\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel)\u001b[0m\n\u001b[0;32m   1205\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1206\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1207\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1208\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1209\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'UrbanSounds8K/processed/fold1.npz'"
     ]
    }
   ],
   "source": [
    "# Pre-process and extract feature from the data\n",
    "parent_dir = 'UrbanSounds8K/audio/'\n",
    "save_dir = \"UrbanSounds8K/processed/\"\n",
    "folds = sub_dirs = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "for sub_dir in sub_dirs:\n",
    "    features, labels = extract_features(parent_dir,sub_dir)\n",
    "    np.savez(\"{0}{1}\".format(save_dir, sub_dir), \n",
    "             features=features, \n",
    "             labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define convolutional network architecture ###\n",
    "def get_network():\n",
    "    num_filters = [24,32,64,128] \n",
    "    pool_size = (2, 2) \n",
    "    kernel_size = (3, 3)  \n",
    "    input_shape = (60, 41, 2)\n",
    "    num_classes = 10\n",
    "    keras.backend.clear_session()\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Conv2D(24, kernel_size,\n",
    "                padding=\"same\", input_shape=input_shape))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(64, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=pool_size))\n",
    "    \n",
    "    model.add(keras.layers.Conv2D(128, kernel_size,\n",
    "                                  padding=\"same\"))\n",
    "    model.add(keras.layers.BatchNormalization())\n",
    "    model.add(keras.layers.Activation(\"relu\"))  \n",
    "\n",
    "    model.add(keras.layers.GlobalMaxPooling2D())\n",
    "    model.add(keras.layers.Dense(128, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=keras.optimizers.Adam(1e-4), \n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "        metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train and evaluate via 10-Folds cross-validation ###\n",
    "accuracies = []\n",
    "folds = np.array(['fold1','fold2','fold3','fold4',\n",
    "                  'fold5','fold6','fold7','fold8',\n",
    "                  'fold9','fold10'])\n",
    "load_dir = \"UrbanSounds8K/processed/\"\n",
    "kf = KFold(n_splits=10)\n",
    "for train_index, test_index in kf.split(folds):\n",
    "    x_train, y_train = [], []\n",
    "    for ind in train_index:\n",
    "        # read features or segments of an audio file\n",
    "        train_data = np.load(\"{0}/{1}.npz\".format(load_dir,folds[ind]), \n",
    "                       allow_pickle=True)\n",
    "        # for training stack all the segments so that they are treated as an example/instance\n",
    "        features = np.concatenate(train_data[\"features\"], axis=0) \n",
    "        labels = np.concatenate(train_data[\"labels\"], axis=0)\n",
    "        x_train.append(features)\n",
    "        y_train.append(labels)\n",
    "    # stack x,y pairs of all training folds \n",
    "    x_train = np.concatenate(x_train, axis = 0).astype(np.float32)\n",
    "    y_train = np.concatenate(y_train, axis = 0).astype(np.float32)\n",
    "    \n",
    "    # for testing we will make predictions on each segment and average them to \n",
    "    # produce signle label for an entire sound clip.\n",
    "    test_data = np.load(\"{0}/{1}.npz\".format(load_dir,\n",
    "                   folds[test_index][0]), allow_pickle=True)\n",
    "    x_test = test_data[\"features\"]\n",
    "    y_test = test_data[\"labels\"]\n",
    "\n",
    "    model = get_network()\n",
    "    model.fit(x_train, y_train, epochs = 50, batch_size = 24, verbose = 0)\n",
    "    \n",
    "    # evaluate on test set/fold\n",
    "    y_true, y_pred = [], []\n",
    "    for x, y in zip(x_test, y_test):\n",
    "        # average predictions over segments of a sound clip\n",
    "        avg_p = np.argmax(np.mean(model.predict(x), axis = 0))\n",
    "        y_pred.append(avg_p) \n",
    "        # pick single label via np.unique for a sound clip\n",
    "        y_true.append(np.unique(y)[0]) \n",
    "    accuracies.append(accuracy_score(y_true, y_pred))    \n",
    "print(\"Average 10 Folds Accuracy: {0}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
